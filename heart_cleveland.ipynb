{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Cleveland\n",
    "A quick tree evaluation of the Heart Diseas Cleveland dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "pyplot.rcParams['figure.dpi'] = 150\n",
    "pyplot.rcParams['savefig.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ultimate aim is to predict whether a patient has heart disease or not. First\n",
    "we load the available data, which contains the information for each patient,\n",
    "including the coding whether the have heart desease (condition == 1) or not\n",
    "(condition == 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_cleveland = pd.read_csv('heart_cleveland_upload.csv')\n",
    "print(heart_cleveland.head())\n",
    "print(heart_cleveland.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract the X (predictors) and Y (condition) values and split them into\n",
    "test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_cleveland.drop(columns=['condition'])\n",
    "Y = heart_cleveland.loc[:, 'condition']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=.2, random_state=42)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start to identify the most powerful predictors we build a basic classification\n",
    "tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "for min_sample_split in range(train_y.size, 2, -1):\n",
    "    heart_tree = tree.DecisionTreeClassifier(max_leaf_nodes=min_sample_split)\n",
    "    heart_tree = heart_tree.fit(train_x, train_y)\n",
    "    pred_y = heart_tree.predict(test_x)\n",
    "    try:\n",
    "        accuracies[accuracy_score(test_y, pred_y)].append(min_sample_split)\n",
    "    except KeyError:\n",
    "        accuracies[accuracy_score(test_y, pred_y)] = [min_sample_split]\n",
    "\n",
    "    if accuracy_score(test_y, pred_y) >= best_accuracy:\n",
    "        best_accuracy = accuracy_score(test_y, pred_y)\n",
    "        best_model = heart_tree\n",
    "\n",
    "print(\"Most accurate model has a maximum of \",\n",
    "      best_model.get_n_leaves(), \" leaf nodes.\")\n",
    "\n",
    "best_pred_y = best_model.predict(test_x)\n",
    "print(\"The accurace of the model is\", accuracy_score(test_y, best_pred_y))\n",
    "\n",
    "tree.plot_tree(best_model, max_depth=2, feature_names=train_x.columns)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8015e832064b0cc05c5951145523b6ca3f400b38f9e1831969b0ba06db48de2f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('heart-cleveland': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
